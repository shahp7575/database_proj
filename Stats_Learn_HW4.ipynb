{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stats Learn - HW4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMmI3tkaCqV3ZkDjhvT69I2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahp7575/database_proj/blob/master/Stats_Learn_HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHd8rZYHfTwb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import scipy.stats as sps\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') \n",
        "\n",
        "# sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import  SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih9oOPgZhRxy"
      },
      "source": [
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fBbepcuUkiE4",
        "outputId": "03d28478-9cea-47ab-f1c0-59250a6020ec"
      },
      "source": [
        "data.target"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ehdKDWG_iSQ5",
        "outputId": "830d3427-ae6c-46c4-b273-dfc90dc026b3"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((150, 4), (150,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leG8vEgghuS5"
      },
      "source": [
        "## Question 1: \n",
        "\n",
        "##### Decision Stump + AdaBoost model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efsvGddChkI4"
      },
      "source": [
        "dec_stump = DecisionTreeClassifier(criterion='entropy', max_depth=1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc7LmvyPhkgQ"
      },
      "source": [
        "pred = np.mean(cross_validate(dec_stump, X, y, cv=10)['test_score'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "L-vUBOCdh8SH",
        "outputId": "eef3d762-5620-4e11-b365-2741d682d488"
      },
      "source": [
        "print(\"Accuracy: \", pred*100)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  66.66666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdnnAONHrpqL"
      },
      "source": [
        "class Boosting:\n",
        "\n",
        "    def __init__(self,dataset,T,test_dataset):\n",
        "        self.dataset = dataset\n",
        "        self.train_X = dataset.data\n",
        "        self.train_y = dataset.target\n",
        "        self.T = T\n",
        "        self.test_dataset = test_dataset\n",
        "        self.alphas = None\n",
        "        self.models = None\n",
        "        self.accuracy = []\n",
        "        self.predictions = None\n",
        "    \n",
        "    def fit(self):\n",
        "        # Set the descriptive features and the target feature\n",
        "        X = self.train_X\n",
        "        y = self.train_y\n",
        "\n",
        "        # Initialize the weights of each sample with wi = 1/N and create a dataframe in which the evaluation is computed\n",
        "        Evaluation = pd.DataFrame(y.copy(), columns=['target'])\n",
        "        Evaluation['weights'] = 1/len(self.dataset) # Set the initial weights w = 1/N\n",
        "        \n",
        "\n",
        "        # Run the boosting algorithm by creating T \"weighted models\"\n",
        "        \n",
        "        alphas = [] \n",
        "        models = []\n",
        "        \n",
        "        for t in range(self.T):\n",
        "\n",
        "            # Train the Decision Stump(s)\n",
        "            Tree_model = DecisionTreeClassifier(criterion=\"entropy\",max_depth=1) # Mind the deth one --> Decision Stump\n",
        "            \n",
        "            # We know that we must train our decision stumps on weighted datasets where the weights depend on the results of\n",
        "            # the previous decision stumps. To accomplish that, we use the 'weights' column of the above created \n",
        "            # 'evaluation dataframe' together with the sample_weight parameter of the fit method.\n",
        "            # The documentation for the sample_weights parameter sais: \"[...] If None, then samples are equally weighted.\"\n",
        "            # Consequently, if NOT None, then the samples are NOT equally weighted and therewith we create a WEIGHTED dataset \n",
        "            # which is exactly what we want to have.\n",
        "            model = Tree_model.fit(X,y,sample_weight=np.array(Evaluation['weights'])) \n",
        "            \n",
        "            # Append the single weak classifiers to a list which is later on used to make the \n",
        "            # weighted decision\n",
        "            models.append(model)\n",
        "            predictions = model.predict(X)\n",
        "            score = model.score(X,y)\n",
        "\n",
        "            # Add values to the Evaluation DataFrame\n",
        "            Evaluation['predictions'] = predictions\n",
        "            Evaluation['evaluation'] = np.where(Evaluation['predictions'] == Evaluation['target'],1,0)\n",
        "            Evaluation['misclassified'] = np.where(Evaluation['predictions'] != Evaluation['target'],1,0)\n",
        "\n",
        "            # Calculate the misclassification rate and accuracy\n",
        "            accuracy = sum(Evaluation['evaluation'])/len(Evaluation['evaluation'])\n",
        "            misclassification = sum(Evaluation['misclassified'])/len(Evaluation['misclassified'])\n",
        "\n",
        "\n",
        "            # Caclulate the error\n",
        "            err = np.sum(Evaluation['weights']*Evaluation['misclassified'])/np.sum(Evaluation['weights'])\n",
        " \n",
        "   \n",
        "            # Calculate the alpha values\n",
        "            alpha = np.log((1-err)/err)\n",
        "            alphas.append(alpha)\n",
        "\n",
        "\n",
        "            # Update the weights wi --> These updated weights are used in the sample_weight parameter\n",
        "            # for the training of the next decision stump. \n",
        "            Evaluation['weights'] *= np.exp(alpha*Evaluation['misclassified'])\n",
        "\n",
        "            #print('The Accuracy of the {0}. model is : '.format(t+1),accuracy*100,'%')\n",
        "            #print('The missclassification rate is: ',misclassification*100,'%')\n",
        "        \n",
        "        self.alphas = alphas\n",
        "        self.models = models\n",
        "            \n",
        "    def predict(self):\n",
        "        X_test = self.test_dataset.data\n",
        "        y_test = self.test_dataset.target\n",
        "    \n",
        "        # With each model in the self.model list, make a prediction \n",
        "        \n",
        "        accuracy = []\n",
        "        predictions = []\n",
        "        \n",
        "        for alpha,model in zip(self.alphas,self.models):\n",
        "            prediction = alpha*model.predict(X_test) # We use the predict method for the single decisiontreeclassifier models in the list\n",
        "            predictions.append(prediction)\n",
        "            self.accuracy.append(np.sum(np.sign(np.sum(np.array(predictions),axis=0))==y_test)/len(predictions[0]))\n",
        "            self.predictions = np.sign(np.sum(np.array(predictions),axis=0))"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwhcG7M8rva-"
      },
      "source": [
        "num_learners = 50\n",
        "data = load_iris()\n",
        "\n",
        "for i in range(num_learners):\n",
        "  model = Boosting(data, i, data)\n",
        "  model.fit()\n",
        "  model.predict()"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "51CmYQGqryQs",
        "outputId": "d6c69bb3-fe08-43c7-c6e6-4c2dc9a9c911"
      },
      "source": [
        "plt.plot(range(len(model.accuracy)), model.accuracy, '-b')"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7efcda925e10>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf8tRDInmXxa"
      },
      "source": [
        "## Question 2: Spam Data\n",
        "\n",
        "##### (a) Try to play with the parametersinteraction.depth(J),shrinkage(ν),bag.fraction(η) andthe number of iterationsM.  Report the best test errors you are able to obtain, together with thecorrespondingJ, ν, ηandM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq2GM2RsmXN7"
      },
      "source": [
        "X = pd.read_csv('spam.txt', sep=' ', header=None)\n",
        "y = pd.read_csv('spam_ind.txt', sep=' ', header=None)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INwjPFodoRpQ"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yy8UmRwoBxG"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEv4I5bzm9p9"
      },
      "source": [
        "def adaboost(depth, shrinkage=0.01, n_iters=10):\n",
        "\n",
        "  clf = AdaBoostClassifier(\n",
        "      DecisionTreeClassifier(max_depth=depth, random_state=42),\n",
        "      n_estimators=n_iters,\n",
        "      learning_rate=shrinkage\n",
        "  )\n",
        "\n",
        "  clf.fit(X_train_scaled, y_train)\n",
        "  y_pred = clf.predict(X_test_scaled)\n",
        "  print(f\"Error AdaBoost with depth {depth}, shrinkage {shrinkage}, n_iters {n_iters}: \", 1 - accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "50OjZ9qVpoFi",
        "outputId": "b7e24047-bb94-4230-d078-b2cb5e960e3e"
      },
      "source": [
        "# depth=1, shrinkage=0.01, n_iters=100\n",
        "adaboost(1, 0.01, 100)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error AdaBoost with depth 1, shrinkage 0.01, n_iters 100:  0.32493483927019984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YDkgTjD8p-S0",
        "outputId": "fcaa71d5-6666-4962-acbe-0b25d269e6f6"
      },
      "source": [
        "# depth=5, shrinkage=0.05, n_iters=200\n",
        "adaboost(5, 0.05, 200)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error AdaBoost with depth 5, shrinkage 0.05, n_iters 200:  0.4005212858384014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PmzOSDBPqHqD",
        "outputId": "2aa9b99a-cae1-4475-9ceb-0133b8b3dea7"
      },
      "source": [
        "# dept=10, shrinkage=0.1, n_iters=100\n",
        "adaboost(10, 0.1, 100)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error AdaBoost with depth 10, shrinkage 0.1, n_iters 100:  0.38575152041702865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rANUR2r5qSSs",
        "outputId": "063d730d-2c2d-40f3-a968-aa934f1fbb7e"
      },
      "source": [
        "# depth=1, shrinkage=0.001, n_iters=200\n",
        "adaboost(1, 0.001, 200)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error AdaBoost with depth 1, shrinkage 0.001, n_iters 200:  0.32319721980886185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35GGsUdjqs62"
      },
      "source": [
        "##### (b) Logistic, SVM, AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "h4FaUr9Qq3qK",
        "outputId": "cf829554-c85d-4650-ee90-c3ed0f461a03"
      },
      "source": [
        "log_reg = LogisticRegression(random_state=42)\n",
        "svc = SVC(random_state=42)\n",
        "\n",
        "# fit logistict\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "log_pred = log_reg.predict(X_test_scaled)\n",
        "print(\"Error on Logisitic Regression: \", 1 - accuracy_score(y_test, log_pred))\n",
        "\n",
        "# fit svm\n",
        "svc.fit(X_train_scaled, y_train)\n",
        "svc_pred = svc.predict(X_test_scaled)\n",
        "print(\"Error on SVMs: \", 1 - accuracy_score(y_test, svc_pred))\n",
        "\n",
        "# adaboost\n",
        "adaboost(1, 0.001, 200)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error on Logisitic Regression:  0.3223284100781929\n",
            "Error on SVMs:  0.32927888792354476\n",
            "Error AdaBoost with depth 1, shrinkage 0.001, n_iters 200:  0.32319721980886185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sx0ujq973fao"
      },
      "source": [
        "## Question 3 Caravan \n",
        "\n",
        "##### (a) Fit a boosting model to the training set withPurchase as the response and the other variables aspredictors.  Use 1,000 trees, and a shrinkage value of 0.01.  Which predictors appear to be the most important?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH19Tne-3peU"
      },
      "source": [
        "caravan = pd.read_csv('https://raw.githubusercontent.com/JWarmenhoven/ISLR-python/master/Notebooks/Data/Caravan.csv')"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "FyYCpAkL36Pe",
        "outputId": "16952fa0-8d1b-4f48-93a0-97e0f017c7a1"
      },
      "source": [
        "caravan.head()"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>MOSTYPE</th>\n",
              "      <th>MAANTHUI</th>\n",
              "      <th>MGEMOMV</th>\n",
              "      <th>MGEMLEEF</th>\n",
              "      <th>MOSHOOFD</th>\n",
              "      <th>MGODRK</th>\n",
              "      <th>MGODPR</th>\n",
              "      <th>MGODOV</th>\n",
              "      <th>MGODGE</th>\n",
              "      <th>MRELGE</th>\n",
              "      <th>MRELSA</th>\n",
              "      <th>MRELOV</th>\n",
              "      <th>MFALLEEN</th>\n",
              "      <th>MFGEKIND</th>\n",
              "      <th>MFWEKIND</th>\n",
              "      <th>MOPLHOOG</th>\n",
              "      <th>MOPLMIDD</th>\n",
              "      <th>MOPLLAAG</th>\n",
              "      <th>MBERHOOG</th>\n",
              "      <th>MBERZELF</th>\n",
              "      <th>MBERBOER</th>\n",
              "      <th>MBERMIDD</th>\n",
              "      <th>MBERARBG</th>\n",
              "      <th>MBERARBO</th>\n",
              "      <th>MSKA</th>\n",
              "      <th>MSKB1</th>\n",
              "      <th>MSKB2</th>\n",
              "      <th>MSKC</th>\n",
              "      <th>MSKD</th>\n",
              "      <th>MHHUUR</th>\n",
              "      <th>MHKOOP</th>\n",
              "      <th>MAUT1</th>\n",
              "      <th>MAUT2</th>\n",
              "      <th>MAUT0</th>\n",
              "      <th>MZFONDS</th>\n",
              "      <th>MZPART</th>\n",
              "      <th>MINKM30</th>\n",
              "      <th>MINK3045</th>\n",
              "      <th>MINK4575</th>\n",
              "      <th>...</th>\n",
              "      <th>PPERSAUT</th>\n",
              "      <th>PBESAUT</th>\n",
              "      <th>PMOTSCO</th>\n",
              "      <th>PVRAAUT</th>\n",
              "      <th>PAANHANG</th>\n",
              "      <th>PTRACTOR</th>\n",
              "      <th>PWERKT</th>\n",
              "      <th>PBROM</th>\n",
              "      <th>PLEVEN</th>\n",
              "      <th>PPERSONG</th>\n",
              "      <th>PGEZONG</th>\n",
              "      <th>PWAOREG</th>\n",
              "      <th>PBRAND</th>\n",
              "      <th>PZEILPL</th>\n",
              "      <th>PPLEZIER</th>\n",
              "      <th>PFIETS</th>\n",
              "      <th>PINBOED</th>\n",
              "      <th>PBYSTAND</th>\n",
              "      <th>AWAPART</th>\n",
              "      <th>AWABEDR</th>\n",
              "      <th>AWALAND</th>\n",
              "      <th>APERSAUT</th>\n",
              "      <th>ABESAUT</th>\n",
              "      <th>AMOTSCO</th>\n",
              "      <th>AVRAAUT</th>\n",
              "      <th>AAANHANG</th>\n",
              "      <th>ATRACTOR</th>\n",
              "      <th>AWERKT</th>\n",
              "      <th>ABROM</th>\n",
              "      <th>ALEVEN</th>\n",
              "      <th>APERSONG</th>\n",
              "      <th>AGEZONG</th>\n",
              "      <th>AWAOREG</th>\n",
              "      <th>ABRAND</th>\n",
              "      <th>AZEILPL</th>\n",
              "      <th>APLEZIER</th>\n",
              "      <th>AFIETS</th>\n",
              "      <th>AINBOED</th>\n",
              "      <th>ABYSTAND</th>\n",
              "      <th>Purchase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 87 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  MOSTYPE  MAANTHUI  MGEMOMV  ...  AFIETS  AINBOED  ABYSTAND  Purchase\n",
              "0           1       33         1        3  ...       0        0         0        No\n",
              "1           2       37         1        2  ...       0        0         0        No\n",
              "2           3       37         1        2  ...       0        0         0        No\n",
              "3           4        9         1        3  ...       0        0         0        No\n",
              "4           5       40         1        4  ...       0        0         0        No\n",
              "\n",
              "[5 rows x 87 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5rIt3yw39F7"
      },
      "source": [
        "X = caravan.iloc[:, 1:-1]\n",
        "y = caravan.iloc[:, -1]\n",
        "\n",
        "X_train = X.iloc[:1000, :]\n",
        "X_test = X.iloc[1000:, :]\n",
        "y_train = y.iloc[:1000]\n",
        "y_test = y.iloc[1000:]"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "G3GQtPb839CP",
        "outputId": "26b22225-63e8-43d0-c956-78590f706428"
      },
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 85), (4822, 85), (1000,), (4822,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d5nyd4K38-u"
      },
      "source": [
        "# preprocessing\n",
        "scaler = StandardScaler()\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "y_train_encoded = encoder.fit_transform(y_train)\n",
        "y_test_encoded = encoder.transform(y_test)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FnNF23H8387D",
        "outputId": "d7f85554-6329-4c67-bb2d-dba0a272de9b"
      },
      "source": [
        "X_train_scaled.shape, X_test_scaled.shape, y_train_encoded.shape, y_test_encoded.shape"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 85), (4822, 85), (1000,), (4822,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4u6poCKY38zz",
        "outputId": "d182330c-2cfa-489f-e97b-0363234d1cae"
      },
      "source": [
        "clf = AdaBoostClassifier(\n",
        "      DecisionTreeClassifier(max_depth=100, random_state=42),\n",
        "      learning_rate=0.01\n",
        "  )\n",
        "clf.fit(X_train_scaled, y_train_encoded)\n",
        "y_pred = clf.predict(X_train_scaled)\n",
        "print(f\"Training Error AdaBoost with depth 100, shrinkage 0.01: \", 1 - accuracy_score(y_train_encoded, y_pred))\n",
        "print(\"Most important predictor: \", X.columns[np.argmax(clf.feature_importances_)])"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Error AdaBoost with depth 100, shrinkage 0.01:  0.0010000000000000009\n",
            "Most important predictor:  MINK3045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RrbjGr4HUpY"
      },
      "source": [
        "##### (b) Predict response on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MOjvt7nH38vR",
        "outputId": "8840f520-9ae6-4012-ed8f-ea471393484f"
      },
      "source": [
        "clf = AdaBoostClassifier(\n",
        "      DecisionTreeClassifier(max_depth=100, random_state=42),\n",
        "      learning_rate=0.01\n",
        "  )\n",
        "clf.fit(X_train_scaled, y_train_encoded)\n",
        "y_pred = clf.predict(X_test_scaled)\n",
        "print(f\"Test Error AdaBoost with depth 100, shrinkage 0.01: \", 1 - accuracy_score(y_test_encoded, y_pred))"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Error AdaBoost with depth 100, shrinkage 0.01:  0.10058067192036502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjrXh3jYHZUC"
      },
      "source": [
        "y_pred_prob = clf.predict_proba(X_test_scaled)\n",
        "\n",
        "purchase_ratio = 0.2\n",
        "y_pred_20 = y_pred_prob[:, 1] > purchase_ratio"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fmA1otSUHjCI",
        "outputId": "e7422844-e32d-4506-f00e-565db69f7641"
      },
      "source": [
        "print(\"Fraction of people predicted to make a purchase if probability of purchase is > 20%: \", y_pred_20.sum())"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fraction of people predicted to make a purchase if probability of purchase is > 20%:  277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9MzLDBXINnV"
      },
      "source": [
        "##### (c) Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "75_6dxIiISmu",
        "outputId": "9ef9784b-192a-4935-ff1f-654beb5135a9"
      },
      "source": [
        "print(\"-\"*100)\n",
        "print(\"\\t\\t\\tLOGISTIC REGRESSION\")\n",
        "print(\"-\"*100)\n",
        "\n",
        "log_reg = LogisticRegression(random_state=42)\n",
        "\n",
        "log_reg.fit(X_train_scaled, y_train_encoded)\n",
        "\n",
        "y_pred = log_reg.predict(X_train_scaled)\n",
        "print(\"Training error: \",  1 - accuracy_score(y_train_encoded, y_pred))\n",
        "\n",
        "y_pred = log_reg.predict(X_test_scaled)\n",
        "print(\"Testing error: \",  1 - accuracy_score(y_test_encoded, y_pred))\n",
        "\n",
        "y_pred_prob = log_reg.predict_proba(X_test_scaled)\n",
        "\n",
        "purchase_ratio = 0.2\n",
        "y_pred_20 = y_pred_prob[:, 1] > purchase_ratio\n",
        "\n",
        "print(\"Fraction of people predicted to make a purchase if probability of purchase is > 20%: \", y_pred_20.sum())"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "\t\t\tLOGISTIC REGRESSION\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Training error:  0.05700000000000005\n",
            "Testing error:  0.06594773952716715\n",
            "Fraction of people predicted to make a purchase if probability of purchase is > 20%:  290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEB9buLoI2VW"
      },
      "source": [
        "Logistic Regression performs slightly better on the test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpC_pLtslMgu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}